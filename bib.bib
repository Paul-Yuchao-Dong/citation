
@online{michaelbetancourtPrincipledBayesianWorkflow2018,
  title = {Towards {{A Principled Bayesian Workflow}}},
  author = {{Michael Betancourt}},
  date = {2018-10},
  url = {https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html#step_six:_analyze_the_joint_ensemble27},
  urldate = {2020-01-16},
  abstract = {Given a probabilistic model and a particular observation, Bayesian inference is straightforward to implement. Inferences, and any decisions based upon them, follow immediately in the form of expectations with respect to the corresponding posterior distribution. Building a probabilistic model that is useful in a given application, however, is a far more open-ended challenge. Unfortunately the process of model building is often ignored in introductory texts, leaving practitioners to piece together their own model building workflow from potentially incomplete or even inconsistent heuristics.

In this case study I introduce a principled workflow for building and evaluating probabilistic models in Bayesian inference. This workflow is based on recent research in collaboration with Dan Simpson, Aki Vehtari, Sean Talts, and others; see, for example, Gabry et al. (2017). The specific workflow that I advocated here, however, is my particular take on this research that is focused on the needs of modeling and inference in the physical sciences. It does not necessarily reflect the perspectives of any of my collaborators and may prove to be limiting in other applications.

Moreover, as this workflow is an active topic of research it is subject to evolution and refinement. Use it at your own risk. But at the same time don’t use at your own risk. Better yet build a calibrated model, infer the relative risks, and then make a principled decision…

We begin with a review of Bayesian inference and then a discussion of what properties we want in a probabilistic model and in what ways we can validate those properties. I then introduce a workflow that implements these validations to guide the development of a useful model, emphasizing the role of each step and the expertise needed to implement them well. Once the workflow has been laid out I demonstrate its application on a seemingly simple analysis that hides a few surprises.},
  file = {C\:\\Users\\paul.dong\\Zotero\\storage\\HZB2NID7\\principled_bayesian_workflow.html},
  langid = {english}
}

@article{schadPrincipledBayesianWorkflow2019,
  title = {Toward a Principled {{Bayesian}} Workflow in Cognitive Science},
  author = {Schad, Daniel J. and Betancourt, Michael and Vasishth, Shravan},
  date = {2019-05-02},
  url = {http://arxiv.org/abs/1904.12765},
  urldate = {2020-01-16},
  abstract = {Experiments in research on memory, language, and in other areas of cognitive science are increasingly being analyzed using Bayesian methods. This has been facilitated by the development of probabilistic programming languages such as Stan, and easily accessible front-end packages such as brms. However, the utility of Bayesian methods ultimately depends on the relevance of the Bayesian model, in particular whether or not it accurately captures the structure of the data and the data analyst's domain expertise. Even with powerful software, the analyst is responsible for verifying the utility of their model. To accomplish this, we introduce a principled Bayesian workflow (Betancourt, 2018) to cognitive science. Using a concrete working example, we describe basic questions one should ask about the model: prior predictive checks, computational faithfulness, model sensitivity, and posterior predictive checks. The running example for demonstrating the workflow is data on reading times with a linguistic manipulation of object versus subject relative sentences. This principled Bayesian workflow also demonstrates how to use domain knowledge to inform prior distributions. It provides guidelines and checks for valid data analysis, avoiding overfitting complex models to noise, and capturing relevant data structure in a probabilistic model. Given the increasing use of Bayesian methods, we aim to discuss how these methods can be properly employed to obtain robust answers to scientific questions. All data and code accompanying this paper are available from https://osf.io/b2vx9/.},
  annotation = {Comment: 65 pages, 16 figures},
  archivePrefix = {arXiv},
  eprint = {1904.12765},
  eprinttype = {arxiv},
  file = {C\:\\Users\\paul.dong\\Zotero\\storage\\IIJ9LFZF\\Schad et al. - 2019 - Toward a principled Bayesian workflow in cognitive.pdf;C\:\\Users\\paul.dong\\Zotero\\storage\\9YHRPP5Z\\1904.html},
  keywords = {Statistics - Methodology},
  primaryClass = {stat}
}


